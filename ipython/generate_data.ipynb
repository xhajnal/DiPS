{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-informed parameter synthesis for population pDTMCs, notebook 4/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of this notebook is the data generation for the case models by simulating the models.\n",
    "1. [Generate the data](#one)\n",
    "\n",
    "There are four things to be setup in this notebook:\n",
    "1. `agents_quantities` / `populations` - set of agents number to be considered,\n",
    "2. `model_types` - set of model types to be considered,\n",
    "3. `dimension_sample_size` - number of samples per parameter,\n",
    "4. `n_samples` - number of samples hence the number of simulations.\n",
    "\n",
    "The following notebook is: `analysis`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"one\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, os, sys, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "print(os.getcwd())\n",
    "\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "data_path = config.get(\"paths\", \"data\")\n",
    "if not os.path.exists(data_path):\n",
    "    raise OSError(\"Directory does not exist: \" + str(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a dimension for each parameter\n",
    "default_10dim_param_space = numpy.random.random((10,5))\n",
    "print(default_10dim_param_space)\n",
    "for row in range(len(default_10dim_param_space)):\n",
    "    # print(row)\n",
    "    if row >= 4:\n",
    "        # print(default_10dim_param_space[row])\n",
    "        default_10dim_param_space[row]=numpy.zeros(5)\n",
    "    elif row >= 2:\n",
    "        default_10dim_param_space[row]=default_10dim_param_space[1]\n",
    "print()\n",
    "print(default_10dim_param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the data by simulating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate_data import generate_experiments_and_data, generate_experiments, generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"synchronous_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [2,3,5,10,20,40]\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_values=[]\n",
    "# for v_p in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#     p_values.append(v_p)\n",
    "# q_values=[]\n",
    "# for v_q in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#     q_values.append(v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOME UNIFORMLY RANDOM SAMPLES PARAMETER VALUES\n",
    "p_values = [0.028502714675268215, 0.45223461506339047, 0.8732745414252937, 0.6855555397734584, 0.13075717833714784]\n",
    "q_values = [0.5057623641293089  , 0.29577906622244676, 0.8440550299528644, 0.8108008054929994, 0.03259111103419188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PASTING IT INTO ONE NUMPY ARRAY\n",
    "default_2dim_param_space = numpy.zeros((2,5))\n",
    "default_2dim_param_space[0] = p_values\n",
    "default_2dim_param_space[1] = q_values\n",
    "default_2dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PERMUTATE default_2dim_param_space\n",
    "param_space = default_2dim_param_space\n",
    "column_values = []\n",
    "for column in range(len(param_space[0])):\n",
    "    for column2 in range(len(param_space[0])):\n",
    "        column_values.append([param_space[0][column],param_space[1][column2]])\n",
    "permutated_default_2dim_param_space = column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutated_default_2dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.array(permutated_default_2dim_param_space).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = default_2dim_param_space\n",
    "for column in range(len(param_space[0])):\n",
    "    column_values = []\n",
    "    for value in param_space[:, column]:\n",
    "        column_values.append(value)\n",
    "    column_values = tuple(column_values)\n",
    "    print(\"parametrisation:\", column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_two_param, Data_two_param = generate_experiments_and_data(model_types,n_samples,populations,dimension_sample_size,default_2dim_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "# Experiments_two_param, Data_two_param = generate_experiments_and_data(model_types,n_samples,populations,dimension_sample_size, numpy.array(permutated_default_2dim_param_space).transpose(), debugging=True)\n",
    "# print(\"  It took\", socket.gethostname(), time.time() - start_time, \"seconds to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took Freya more than 6 days to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this process took a while so we have pickled the data and we load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(Experiments_two_param,open(os.path.join(data_path,\"Experiments_two_param.p\"), \"wb\" ))\n",
    "# pickle.dump(Data_two_param,open(os.path.join(data_path,\"Data_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load import load_pickled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3 = load_pickled_data(\"Data_two_param\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANAGING THE \"parallel_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in D3.keys():\n",
    "    if \"synchronous_parallel_\" in key:\n",
    "        print(key)\n",
    "        key2 = []\n",
    "        for key_item in key:\n",
    "            key2.append(key_item) \n",
    "        key2[0]=\"synchronous_\"\n",
    "        key2= tuple(key2)\n",
    "        print(key2)\n",
    "        spam = D3[key] \n",
    "        del D3[key]\n",
    "        D3[key2]=spam        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(D3,open(os.path.join(data_path,\"Data_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the used structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3[('synchronous_', 2, 3500, 0.028502714675268215, 0.5057623641293089)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(D3.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFORMATING THE D3 DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D8 = {}\n",
    "for item in D3.keys():\n",
    "    print(item[0])\n",
    "    try:\n",
    "        print(D8[item[0]])\n",
    "        try:\n",
    "            print(D8[item[0]][item[1]])\n",
    "            try:\n",
    "                print(D8[item[0]][item[1]][item[2]])\n",
    "                try:\n",
    "                    print(D8[item[0]][item[1]][item[2]][item[3],item[4]])\n",
    "                except:\n",
    "                    D8[item[0]][item[1]][item[2]][item[3],item[4]] = D3[item]\n",
    "            except:\n",
    "                D8[item[0]][item[1]][item[2]] = {}\n",
    "        except:\n",
    "            D8[item[0]][item[1]] = {}\n",
    "    except:\n",
    "        D8[item[0]] = {}   \n",
    "D8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFORMATING THE NEW DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_two_param_20 = pickle.load(open(os.path.join(data_path,\"Data_two_param_20.p\"), \"rb\" ))\n",
    "Data_two_param_40 = pickle.load(open(os.path.join(data_path,\"Data_two_param_40.p\"), \"rb\" ))\n",
    "D9 = {}\n",
    "\n",
    "for item1 in Data_two_param_20.keys():\n",
    "    for item2 in Data_two_param_20[item1].keys():\n",
    "        for item3 in Data_two_param_20[item1][item2].keys():\n",
    "            for item4 in Data_two_param_20[item1][item2][item3].keys():\n",
    "                # print(Data_two_param_20[item1][item2][item3][item4])\n",
    "                D9[(item1,item2,item3,item4)] = Data_two_param_20[item1][item2][item3][item4]\n",
    "                \n",
    "for item1 in Data_two_param_40.keys():\n",
    "    for item2 in Data_two_param_40[item1].keys():\n",
    "        for item3 in Data_two_param_40[item1][item2].keys():\n",
    "            for item4 in Data_two_param_40[item1][item2][item3].keys():\n",
    "                # print(Data_two_param_40[item1][item2][item3][item4])\n",
    "                D9[(item1,item2,item3,item4)] = Data_two_param_40[item1][item2][item3][item4]\n",
    "\n",
    "D3 = pickle.load(open(os.path.join(data_path,\"Data_two_param.p\"), \"rb\" ))\n",
    "\n",
    "for item in D3.keys():\n",
    "    spam = D3[item]\n",
    "    del(D3[item])\n",
    "    item = (item[0].split(\"p\")[0], item[1], item[2], item[3], item[4])\n",
    "    D3[item] = spam\n",
    "\n",
    "D9.update(D3)\n",
    "pickle.dump(D9,open(os.path.join(data_path,\"Data_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D9.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_two_param_20 = pickle.load(open(os.path.join(data_path,\"Experiments_two_param_20.p\"), \"rb\" ))\n",
    "Experiments_two_param_40 = pickle.load(open(os.path.join(data_path,\"Experiments_two_param_40.p\"), \"rb\" ))\n",
    "D9 = {}\n",
    "\n",
    "for item1 in Experiments_two_param_20.keys():\n",
    "    for item2 in Experiments_two_param_20[item1].keys():\n",
    "        for item3 in Experiments_two_param_20[item1][item2].keys():\n",
    "            for item4 in Experiments_two_param_20[item1][item2][item3].keys():\n",
    "                # print(Experiments_two_param_20[item1][item2][item3][item4])\n",
    "                D9[(item1,item2,item3,item4)] = Experiments_two_param_20[item1][item2][item3][item4]\n",
    "                \n",
    "for item1 in Experiments_two_param_40.keys():\n",
    "    for item2 in Experiments_two_param_40[item1].keys():\n",
    "        for item3 in Experiments_two_param_40[item1][item2].keys():\n",
    "            for item4 in Experiments_two_param_40[item1][item2][item3].keys():\n",
    "                # print(Experiments_two_param_40[item1][item2][item3][item4])\n",
    "                D9[(item1,item2,item3,item4)] = Experiments_two_param_40[item1][item2][item3][item4]\n",
    "\n",
    "D3 = pickle.load(open(os.path.join(data_path,\"Experiments_two_param.p\"), \"rb\" ))\n",
    "\n",
    "for item in D3.keys():\n",
    "    spam = D3[item]\n",
    "    del(D3[item])\n",
    "    item = (item[0].split(\"p\")[0], item[1], item[2], item[3], item[4])\n",
    "    D3[item] = spam\n",
    "\n",
    "D9.update(D3)\n",
    "pickle.dump(D9,open(os.path.join(data_path,\"Experiments_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D9.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFORMATING THE D3 DICTIONARY VOL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D6 = {}\n",
    "for item in D3.keys():\n",
    "    print(item)\n",
    "    print(item[0:3])\n",
    "    print(item[3:5])\n",
    "    try:\n",
    "        print(D6[item[0:3]])\n",
    "    except:\n",
    "        D6[item[0:3]] = {}\n",
    "    D6[item[0:3]][item[3:5]] = D3[item]\n",
    "    print(D3[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D6[('synchronous_', 2, 3500)].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(D6[('synchronous_', 2, 3500)].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments_one_point_step_down_10dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"synchronous_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point_step_down_10dim_param_space = numpy.zeros((10,1))\n",
    "for i in range(0,4):\n",
    "    one_point_step_down_10dim_param_space[i] = [0.1]\n",
    "for i in range(4,10):\n",
    "    one_point_step_down_10dim_param_space[i] = [0]\n",
    "one_point_step_down_10dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_one_point_step_down_10dim_param_space, Data_one_point_step_down_10dim_param_space = generate_experiments_and_data(model_types,n_samples,populations,dimension_sample_size,one_point_step_down_10dim_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump( Experiments_one_point_step_down_10dim_param_space,open(os.path.join(data_path,\"Experiments_one_point_step_down_10dim_param_space.p\"), \"wb\" ))\n",
    "# pickle.dump( Data_one_point_step_down_10dim_param_space,open(os.path.join(data_path,\"Data_one_point_step_down_10dim_param_space.p\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_one_point_step_down_10dim_param_space = pickle.load(open(os.path.join(data_path,\"Experiments_one_point_step_down_10dim_param_space.p\"), \"rb\" ))\n",
    "Data_one_point_step_down_10dim_param_space = pickle.load(open(os.path.join(data_path,\"Data_one_point_step_down_10dim_param_space.p\"), \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"semisynchronous_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [2,3,5,10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point_linear_param_space  = numpy.zeros((10,1))\n",
    "one_point_linear_param_space[0] = [0.4]\n",
    "for i in range(1,10):\n",
    "    one_point_linear_param_space[i] = [i*0.1]\n",
    "one_point_linear_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_one_point_linear_param_space, Data_one_point_linear_param_space = generate_experiments_and_data(model_types,n_samples,populations,dimension_sample_size,one_point_linear_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(Experiments_one_point_linear_param_space['multiparam_semisynchronous_'][10][3500][(0.4,0.1,  0.2,  0.30000000000000004,  0.4,  0.5,  0.6000000000000001,  0.7000000000000001,  0.8,  0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_one_point_linear_param_space['multiparam_semisynchronous_'][2][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump( Experiments_one_point_linear_param_space,open(os.path.join(data_path,\"Experiments_one_point_linear_param_space.p\"), \"wb\" ))\n",
    "# pickle.dump( Data_one_point_linear_param_space,open(os.path.join(data_path,\"Data_one_point_linear_param_space.p\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_one_point_linear_param_space = pickle.load(open(os.path.join(data_path,\"Experiments_one_point_linear_param_space.p\"), \"rb\" ))\n",
    "Data_one_point_linear_param_space = pickle.load(open(os.path.join(data_path,\"Data_one_point_linear_param_space.p\"), \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One point linear bee models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"bee_multiparam_synchronous_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point_linear_param_space  = numpy.zeros((10,1))\n",
    "one_point_linear_param_space[0] = [0.1]\n",
    "for i in range(1,10):\n",
    "    one_point_linear_param_space[i] = [i*0.05+0.1]\n",
    "one_point_linear_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_bee_one_point_linear_param_space, Data_bee_one_point_linear_param_space = generate_experiments_and_data(model_types,n_samples,populations,dimension_sample_size, sim_length=max(populations), modular_param_space=one_point_linear_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump( Experiments_bee_one_point_linear_param_space,open(os.path.join(data_path,\"Experiments_bee_one_point_linear_param_space.p\"), \"wb\" ))\n",
    "# pickle.dump( Data_bee_one_point_linear_param_space,open(os.path.join(data_path,\"Data_bee_one_point_linear_param_space.p\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_bee_one_point_linear_param_space = pickle.load(open(os.path.join(data_path,\"Experiments_bee_one_point_linear_param_space.p\"), \"rb\" ))\n",
    "Data_bee_one_point_linear_param_space = pickle.load(open(os.path.join(data_path,\"Data_bee_one_point_linear_param_space.p\"), \"rb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
