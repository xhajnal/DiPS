{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, os, sys, subprocess,re, time, socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "prism_path = config.get(\"paths\", \"prism_path\")\n",
    "data_path = config.get(\"paths\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "due to large time consumed made separately for each pop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"models\"]\n",
    "model_types = [\"synchronous_parallel_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [2,3,5,10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate param values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values=[]\n",
    "#for v_p in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#    p_values.append(v_p)\n",
    "#q_values=[]\n",
    "#for v_q in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#    q_values.append(v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0.028502714675268215, 0.45223461506339047, 0.8732745414252937, 0.6855555397734584, 0.13075717833714784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values = [0.5057623641293089  , 0.29577906622244676, 0.8440550299528644, 0.8108008054929994, 0.03259111103419188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.chdir(cwd)\n",
    "from src.mc_prism import call_prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the data by simulating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_sample = max(n_samples)\n",
    "\n",
    "# start_time = time.time()\n",
    "# i=1\n",
    "# Experiments={}\n",
    "# for folder in folders:\n",
    "#     for model_type in model_types:\n",
    "#         if model_type == \"synchronous_parallel_\":\n",
    "#             sim_lenght=2\n",
    "#         for N in populations:\n",
    "#             if model_type == \"semisynchronous_parallel_\":\n",
    "#                 sim_lenght= 2*N\n",
    "#             if model_type == \"asynchronous_parallel_\":\n",
    "#                 sim_lenght= 2*N\n",
    "#             model = model_type+str(N)+\".pm\"\n",
    "#             for v_p in p_values:\n",
    "#                 for v_q in q_values:\n",
    "#                     Experiments[(model_type,N,max_sample,v_p,v_q)]=[]\n",
    "#                     #file = open(\"path_{}_{}_{}_{}_{}.txt\".format(model_type,N,n_sample,v_p,v_q),\"w+\")\n",
    "#                     #file.close()\n",
    "#                     for sample in range(max_sample):\n",
    "#                         if i==1:\n",
    "#                             ## dummy path file for prism output\n",
    "#                             path_file=f\"path_{model_type}{N}_{max_sample}_{v_p}_{v_q}.txt\"\n",
    "#                             ## here is the PRISM called\n",
    "#                             call_prism(f\"{model} -const p={v_p},q={v_q} -simpath {str(sim_lenght)} {path_file}\", silent=True, prism_output_path=cwd)\n",
    "#                             ## parse the dummy file\n",
    "#                             file = open(path_file,\"rt\")\n",
    "#                             last_line = file.readlines()[-1]\n",
    "#                             #print(last_line)\n",
    "#                             ## close and remove dummy file\n",
    "#                             file.close()  \n",
    "#                             os.remove(path_file)\n",
    "#                             ## append the experiment\n",
    "#                             Experiments[(model_type,N,max_sample,v_p,v_q)].append(sum( list(map(lambda x: int(x), last_line.split(\" \")[2:-1]))))\n",
    "#                         #i=0\n",
    "#                     #print(model_type,N,max_sample,v_p,v_q)\n",
    "#                     print(Experiments[(model_type,N,max_sample,v_p,v_q)])\n",
    "#                     for n_sample in n_samples:\n",
    "#                         if n_sample is not max_sample:\n",
    "#                             Experiments[(model_type,N,n_sample,v_p,v_q)] = Experiments[(model_type,N,max_sample,v_p,v_q)][:n_sample]\n",
    "#                             print(Experiments[(model_type,N,n_sample,v_p,v_q)])\n",
    "# print(\"  It took\", socket.gethostname(), time.time() - start_time, \"seconds to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took Freya 6 days to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this process took a while so we have pickled the data and we load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump( D,open(os.path.join(data_path,\"Experiments_two_param.p\", \"wb\" )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments = pickle.load(open(os.path.join(data_path,\"Experiments_two_param.p\"), \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Experiments[('synchronous_parallel_',10,100,0.028502714675268215,0.5057623641293089)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute frequency - hence estimated probability of reaching respective bSCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data={}\n",
    "for folder in folders:\n",
    "    for model_type in model_types:\n",
    "        for N in populations:\n",
    "            model = os.path.join(folder,model_type+str(N)+\".pm\")\n",
    "            for v_p in p_values:\n",
    "                for v_q in q_values:\n",
    "                    for n_sample in n_samples:\n",
    "                        Data[(model_type,N,n_sample,v_p,v_q)]=[]\n",
    "                        for i in range(N+1):\n",
    "                            Data[(model_type,N,n_sample,v_p,v_q)].append(len(list(filter(lambda x: x ==i ,Experiments[(model_type,N,n_sample,v_p,v_q)])))/n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[('synchronous_parallel_',10,100,0.028502714675268215,0.5057623641293089)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Data,open(os.path.join(data_path,\"Experiments_freq_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been checked by: \n",
    "\n",
    "`add name here` on `add date here`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
