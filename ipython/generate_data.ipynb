{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, os, sys, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a dimension for each parameter\n",
    "default_10dim_param_space = numpy.random.random((10,5))\n",
    "print(default_10dim_param_space)\n",
    "for row in range(len(default_10dim_param_space)):\n",
    "    #print(row)\n",
    "    if row >= 4:\n",
    "        #print(default_10dim_param_space[row])\n",
    "        default_10dim_param_space[row]=numpy.zeros(5)\n",
    "    elif row >= 2:\n",
    "        default_10dim_param_space[row]=default_10dim_param_space[1]\n",
    "print()\n",
    "print(default_10dim_param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the data by simulating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.getcwd())\n",
    "os.chdir(cwd)\n",
    "from src.mc_prism import call_prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generate_data import generate_experiments_n_data,generate_experiments,generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiments_n_data(model_types, multiparam, n_samples, populations, dimension_sample_size,\n",
    "                                modular_param_space=None, debugging=False):\n",
    "    \"\"\"Generate experiment data for given settings\n",
    "\n",
    "    Args\n",
    "    ------\n",
    "    model_types: list of model types\n",
    "    multiparam: yes if multiparam should be used\n",
    "    n_samples: list of sample sizes\n",
    "    populations: list of agent populations\n",
    "    dimension_sample_size: number of samples of in each paramter dimension to be used\n",
    "    modular_param_space: parameter space to be used\n",
    "    \"\"\"\n",
    "    max_sample = max(n_samples)\n",
    "    start_time = time.time()\n",
    "\n",
    "    i = 1\n",
    "    Experiments = {}\n",
    "    Data = {}\n",
    "    for model_type in model_types:\n",
    "        if multiparam:\n",
    "            model_type = \"multiparam_\" + model_type\n",
    "        if debugging:\n",
    "            print(\"model_type\",model_type)\n",
    "        if \"synchronous\" in model_type:\n",
    "            sim_lenght = 2\n",
    "        Data[model_type] = {}\n",
    "        Experiments[model_type] = {}\n",
    "        for N in populations:\n",
    "            if \"semisynchronous\" in model_type:\n",
    "                sim_lenght = 2 * N\n",
    "            if \"asynchronous\" in model_type:\n",
    "                sim_lenght = 2 * N\n",
    "            parameters = [\"p\"]\n",
    "            if multiparam:\n",
    "                for agents in range(1, N):\n",
    "                    parameters.append(\"q\" + str(agents))\n",
    "            else:\n",
    "                parameters.append(\"q\")\n",
    "            print(\"parameters: \", parameters)\n",
    "\n",
    "            ## modulate parameter space\n",
    "            if modular_param_space is not None:\n",
    "                param_space = modular_param_space\n",
    "            else:\n",
    "                param_space = numpy.random.random((len(parameters), dimension_sample_size))\n",
    "\n",
    "            print(\"parameter space:\")\n",
    "            print(param_space)\n",
    "\n",
    "            model = model_type + str(N) + \".pm\"\n",
    "\n",
    "            Experiments[model_type][N] = {}\n",
    "            Data[model_type][N] = {}\n",
    "            for n_sample in n_samples:\n",
    "                Experiments[model_type][N][n_sample] = {}\n",
    "                Data[model_type][N][n_sample] = {}\n",
    "\n",
    "            #print(len(param_space[0]))\n",
    "            for column in range(len(param_space[0])):\n",
    "                column_values = []\n",
    "                for value in param_space[:, column]:\n",
    "                    column_values.append(value)\n",
    "                column_values = tuple(column_values)\n",
    "                print(\"parametrisation:\",column_values)\n",
    "                for n_sample in n_samples:\n",
    "                    Experiments[model_type][N][n_sample][column_values] = []\n",
    "                    Data[model_type][N][n_sample][column_values] = []\n",
    "                # file = open(\"path_{}_{}_{}_{}_{}.txt\".format(model_type,N,max_sample,v_p,v_q),\"w+\")\n",
    "                # file.close()\n",
    "                for sample in range(1, max_sample + 1):\n",
    "                    ## dummy path file for prism output\n",
    "                    parameter_values = \"\"\n",
    "                    prism_parameter_values = \"\"\n",
    "\n",
    "                    for value in range(len(column_values)):\n",
    "                        parameter_values = parameter_values + \"_\" + str(column_values[value])\n",
    "                        prism_parameter_values = prism_parameter_values + str(parameters[value]) + \"=\" + str(\n",
    "                            column_values[value]) + \",\"\n",
    "                    prism_parameter_values = prism_parameter_values[:-1]\n",
    "                    # print(parameter_values)\n",
    "                    # print(prism_parameter_values)\n",
    "\n",
    "                    ## more profound path name here\n",
    "                    ## path_file = f\"path_{model_type}{N}_{max_sample}_{parameter_values}.txt\"\n",
    "                    path_file = \"dummy_path\" + str(time.time()) + \".txt\"\n",
    "                    # print(path_file)\n",
    "                    if debugging:\n",
    "                        print(f\"{model} -const {prism_parameter_values} -simpath {str(sim_lenght)} {path_file}\")\n",
    "\n",
    "                    ## here is the PRISM called\n",
    "                    call_prism(f\"{model} -const {prism_parameter_values} -simpath {str(sim_lenght)} {path_file}\",\n",
    "                               silent=True, prism_output_path=cwd, std_output_path=None)\n",
    "                    ## parse the dummy file\n",
    "                    file = open(path_file, \"rt\")\n",
    "                    last_line = file.readlines()[-1]\n",
    "\n",
    "                    ## close dummy file\n",
    "                    file.close()\n",
    "\n",
    "                    ## append the experiment\n",
    "                    state = sum(list(map(lambda x: int(x), last_line.split(\" \")[2:-1])))\n",
    "\n",
    "                    ## some error occured\n",
    "                    if state > N or debugging or \"2\" in last_line.split(\" \")[2:-1]:\n",
    "                        print(last_line[:-1])\n",
    "                        print(\"state:\", state)\n",
    "                        print()\n",
    "                    else:  ## if no error remove the file\n",
    "                        os.remove(path_file)\n",
    "                    for n_sample in n_samples:\n",
    "                        if sample <= n_sample:\n",
    "                            Experiments[model_type][N][n_sample][column_values].append(state)\n",
    "                for n_sample in n_samples:\n",
    "                    for i in range(N + 1):\n",
    "                        Data[model_type][N][n_sample][column_values].append(len(list(\n",
    "                            filter(lambda x: x == i, Experiments[model_type][N][n_sample][column_values]))) / n_sample)\n",
    "                print(\"states:\", Experiments[model_type][N][max_sample][column_values])\n",
    "\n",
    "    print(\"  It took\", socket.gethostname(), time.time() - start_time, \"seconds to run\")\n",
    "    return Experiments, Data\n",
    "\n",
    "\n",
    "def generate_experiments(model_types, multiparam, n_samples, populations, dimension_sample_size,\n",
    "                         modular_param_space=None):\n",
    "    \"\"\"Generate experiment data for given settings\n",
    "    Args\n",
    "    ------\n",
    "    model_types: list of model types\n",
    "    multiparam: yes if multiparam should be used\n",
    "    n_samples: list of sample sizes\n",
    "    populations: list of agent populations\n",
    "    dimension_sample_size: number of samples of in each paramter dimension to be used\n",
    "    modular_param_space: parameter space to be used\n",
    "    \"\"\"\n",
    "    return generate_experiments_n_data(model_types, multiparam, n_samples, populations, dimension_sample_size,\n",
    "                                       modular_param_space)[0]\n",
    "\n",
    "\n",
    "def generate_data(model_types, multiparam, n_samples, populations, dimension_sample_size, modular_param_space=None):\n",
    "    \"\"\"Generate experiment data for given settings\n",
    "\n",
    "    Args\n",
    "    ------\n",
    "    model_types: list of model types\n",
    "    multiparam: yes if multiparam should be used\n",
    "    n_samples: list of sample sizes\n",
    "    populations: list of agent populations\n",
    "    dimension_sample_size: number of samples of in each paramter dimension to be used\n",
    "    modular_param_space: parameter space to be used\n",
    "    \"\"\"\n",
    "    return generate_experiments_n_data(model_types, multiparam, n_samples, populations, dimension_sample_size,\n",
    "                                       modular_param_space)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparam = False\n",
    "model_types = [\"synchronous_parallel_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [2,3,5,10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_values=[]\n",
    "#for v_p in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#    p_values.append(v_p)\n",
    "#q_values=[]\n",
    "#for v_q in numpy.random.uniform(0.0, 1.0,dimension_sample_size):\n",
    "#    q_values.append(v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [0.028502714675268215, 0.45223461506339047, 0.8732745414252937, 0.6855555397734584, 0.13075717833714784]\n",
    "q_values = [0.5057623641293089  , 0.29577906622244676, 0.8440550299528644, 0.8108008054929994, 0.03259111103419188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_2dim_param_space = numpy.zeros((2,5))\n",
    "default_2dim_param_space[0] = p_values\n",
    "default_2dim_param_space[1] = q_values\n",
    "default_2dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_two_param, Data_two_param = generate_experiments_n_data(model_types,multiparam,n_samples,populations,dimension_sample_size,default_2dim_param_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took Freya 6 days to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this process took a while so we have pickled the data and we load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump( Experiments_two_param,open(os.path.join(data_path,\"Experiments_two_param.p\", \"wb\" )))\n",
    "# pickle.dump(Data_two_param,open(os.path.join(data_path,\"Data_two_param.p\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_two_param = pickle.load(open(os.path.join(data_path,\"Experiments_two_param.p\"), \"rb\" ))\n",
    "Data_two_param = pickle.load(open(os.path.join(data_path,\"Data_two_param.p\"), \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments_one_point_step_down_10dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparam = True\n",
    "model_types = [\"synchronous_parallel_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point_step_down_10dim_param_space = numpy.zeros((10,1))\n",
    "for i in range(0,4):\n",
    "    one_point_step_down_10dim_param_space[i] = [0.1]\n",
    "for i in range(4,10):\n",
    "    one_point_step_down_10dim_param_space[i] = [0]\n",
    "one_point_step_down_10dim_param_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments_one_point_step_down_10dim_param_space, Data_one_point_step_down_10dim_param_space = generate_experiments_n_data(model_types,multiparam,n_samples,populations,dimension_sample_size,one_point_step_down_10dim_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump( Experiments_one_point_step_down_10dim_param_space,open(os.path.join(data_path,\"Experiments_one_point_step_down_10dim_param_space.p\"), \"wb\" ))\n",
    "#pickle.dump( Data_one_point_step_down_10dim_param_space,open(os.path.join(data_path,\"Data_one_point_step_down_10dim_param_space.p\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments_one_point_step_down_10dim_param_space = pickle.load(open(os.path.join(data_path,\"Experiments_one_point_step_down_10dim_param_space.p\"), \"rb\" ))\n",
    "Data_one_point_step_down_10dim_param_space = pickle.load(open(os.path.join(data_path,\"Data_one_point_step_down_10dim_param_space.p\"), \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear generations TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparam = True\n",
    "model_types = [\"synchronous_parallel_\"]\n",
    "n_samples = [3500,1500,100]\n",
    "populations = [10]\n",
    "dimension_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point_linear_10dim_param_space  = numpy.zeros((10,1))\n",
    "one_point_linear_10dim_param_space[0] = [0.1]\n",
    "for i in range(1,10):\n",
    "    one_point_linear_10dim_param_space[i] = [0.1 + i*0.5]\n",
    "one_point_linear_10dim_param_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
